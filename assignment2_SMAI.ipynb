{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN classifier in Iris and robot dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use of KNN classifier\n",
    "     1.Getting all neighbours for that test point\n",
    "         neighbours=get_neighbors(train_dataset, test_sample,k)\n",
    "\t 2.Extracting class with highest number of votes among those neighbours\n",
    "         major_class= get_votes(neighbors)\n",
    "     3.appending classfication for that result\n",
    "         prediction_list.append(major_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mlt\n",
    "import csv\n",
    "import random\n",
    "import operator\n",
    "import math\n",
    "from sklearn.metrics.pairwise import cosine_similarity as cos\n",
    "from sklearn.metrics import precision_recall_fscore_support as score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.2</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.4</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3               4\n",
       "0  5.1  3.5  1.4  0.2     Iris-setosa\n",
       "1  6.3  3.3  6.0  2.5  Iris-virginica\n",
       "2  5.0  3.0  1.6  0.2     Iris-setosa\n",
       "3  6.2  2.8  4.8  1.8  Iris-virginica\n",
       "4  6.4  3.1  5.5  1.8  Iris-virginica"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df=[]\n",
    "validation_df=[]\n",
    "split = 0.2\n",
    "df=pd.read_csv('Iris.csv',header=None)\n",
    "dataset=list(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### splitting data as train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide(df,validation_data_size):\n",
    "    indices = df.index.tolist()\n",
    "    validation_data_size=round(validation_data_size*len(df))\n",
    "    validation_indices = random.sample(population=indices, k=validation_data_size)\n",
    "    train_data = df.drop(validation_indices)\n",
    "    validation_data = df.loc[validation_indices]\n",
    "    return train_data,validation_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "train_df,validation_df = divide(df,validation_data_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting dataframe into list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "['Iris-versicolor' 'Iris-virginica' 'Iris-setosa' 'Iris-versicolor'\n",
      " 'Iris-virginica' 'Iris-setosa' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-versicolor' 'Iris-setosa'\n",
      " 'Iris-versicolor' 'Iris-setosa' 'Iris-virginica' 'Iris-versicolor'\n",
      " 'Iris-setosa' 'Iris-setosa' 'Iris-versicolor' 'Iris-virginica'\n",
      " 'Iris-versicolor' 'Iris-virginica' 'Iris-setosa' 'Iris-virginica'\n",
      " 'Iris-virginica' 'Iris-virginica']\n"
     ]
    }
   ],
   "source": [
    "train_data=train_df.values\n",
    "validation_data=validation_df.values\n",
    "print(type(validation_data))\n",
    "print(validation_data[:,-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### getting Euclidean  distance,manhattan distance and cosine similarity between test entry and train entry(both input as list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_euclidean_distance(test_entry,train_entry):\n",
    "    distance = 0\n",
    "    # we should neglect last entry which is target label\n",
    "    for i in range(len(train_entry)-1):\n",
    "        distance += pow((test_entry[i]-train_entry[i]),2)\n",
    "    return math.sqrt(distance)\n",
    "\n",
    "def get_cosine_similarity(test_entry,train_entry):\n",
    "    train=np.array(train_entry[:-1])\n",
    "    test=np.array(test_entry[:-1])\n",
    "    dot_product = np.dot(test,train)\n",
    "    norm_train = np.linalg.norm(train)\n",
    "    norm_test = np.linalg.norm(test)\n",
    "    return 1-(dot_product / (norm_train * norm_test))\n",
    "\n",
    "def get_manhattan_distance(test_entry,train_entry):\n",
    "    distance=0\n",
    "    for i in range(len(train_entry)-1):\n",
    "        distance += abs(test_entry[i]-train_entry[i])\n",
    "    return math.sqrt(distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting neighbours for the test instance (one row from test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neighbours(train_data,test_entry,k):\n",
    "    neighbour_distances = []\n",
    "    for train_entry in train_data:\n",
    "        #dist = get_euclidean_distance(test_entry,train_entry)\n",
    "        #dist=get_manhattan_distance(test_entry,train_entry)\n",
    "        dist=get_cosine_similarity(test_entry,train_entry)\n",
    "        neighbour_distances.append((train_entry,dist))\n",
    "    neighbour_distances.sort(key=operator.itemgetter(1))\n",
    "    k_closest_neighbors = []\n",
    "    for i in range(k):\n",
    "        #saving the neighbors entries so we can extract the last column while deciding major class in \n",
    "        #get_votes function\n",
    "        k_closest_neighbors.append(neighbour_distances[i][0])\n",
    "    return k_closest_neighbors\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  get major feature from k_closest_neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_votes(neighbors):\n",
    "    votes_dict = {}\n",
    "    for i in neighbors:\n",
    "        v=i[-1]\n",
    "        if v in votes_dict:\n",
    "            votes_dict[v] += 1\n",
    "        else:\n",
    "            votes_dict[v]=1\n",
    "    sorted_votes = sorted(votes_dict.items(), key=operator.itemgetter(1),reverse=True)\n",
    "    return sorted_votes[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_accuracy function takes input as classified list and actual list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(pred,actual):\n",
    "    a,b,c,d=score(actual,pred)  \n",
    "    \n",
    "    #calculation of precision ,recall and F1 score\n",
    "    print(\"precision:\",a)\n",
    "    print(\"recall:\",b)\n",
    "    print(\"fscore:\",c)\n",
    "    return a\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the  above functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classified: Iris-versicolor\n",
      "actual label: Iris-versicolor\n",
      "Correct classification\n",
      "classified: Iris-virginica\n",
      "actual label: Iris-virginica\n",
      "Correct classification\n",
      "classified: Iris-setosa\n",
      "actual label: Iris-setosa\n",
      "Correct classification\n",
      "classified: Iris-versicolor\n",
      "actual label: Iris-versicolor\n",
      "Correct classification\n",
      "classified: Iris-virginica\n",
      "actual label: Iris-virginica\n",
      "Correct classification\n",
      "classified: Iris-setosa\n",
      "actual label: Iris-setosa\n",
      "Correct classification\n",
      "classified: Iris-versicolor\n",
      "actual label: Iris-versicolor\n",
      "Correct classification\n",
      "classified: Iris-versicolor\n",
      "actual label: Iris-versicolor\n",
      "Correct classification\n",
      "classified: Iris-setosa\n",
      "actual label: Iris-setosa\n",
      "Correct classification\n",
      "classified: Iris-setosa\n",
      "actual label: Iris-setosa\n",
      "Correct classification\n",
      "classified: Iris-setosa\n",
      "actual label: Iris-setosa\n",
      "Correct classification\n",
      "classified: Iris-versicolor\n",
      "actual label: Iris-versicolor\n",
      "Correct classification\n",
      "classified: Iris-setosa\n",
      "actual label: Iris-setosa\n",
      "Correct classification\n",
      "classified: Iris-versicolor\n",
      "actual label: Iris-versicolor\n",
      "Correct classification\n",
      "classified: Iris-setosa\n",
      "actual label: Iris-setosa\n",
      "Correct classification\n",
      "classified: Iris-virginica\n",
      "actual label: Iris-virginica\n",
      "Correct classification\n",
      "classified: Iris-versicolor\n",
      "actual label: Iris-versicolor\n",
      "Correct classification\n",
      "classified: Iris-setosa\n",
      "actual label: Iris-setosa\n",
      "Correct classification\n",
      "classified: Iris-setosa\n",
      "actual label: Iris-setosa\n",
      "Correct classification\n",
      "classified: Iris-versicolor\n",
      "actual label: Iris-versicolor\n",
      "Correct classification\n",
      "classified: Iris-virginica\n",
      "actual label: Iris-virginica\n",
      "Correct classification\n",
      "classified: Iris-versicolor\n",
      "actual label: Iris-versicolor\n",
      "Correct classification\n",
      "classified: Iris-virginica\n",
      "actual label: Iris-virginica\n",
      "Correct classification\n",
      "classified: Iris-setosa\n",
      "actual label: Iris-setosa\n",
      "Correct classification\n",
      "classified: Iris-virginica\n",
      "actual label: Iris-virginica\n",
      "Correct classification\n",
      "classified: Iris-virginica\n",
      "actual label: Iris-virginica\n",
      "Correct classification\n",
      "classified: Iris-virginica\n",
      "actual label: Iris-virginica\n",
      "Correct classification\n",
      "Tests: 27\n",
      "Correct: 27\n",
      "Accuracy: 1.0\n",
      "precision: [1. 1. 1.]\n",
      "recall: [1. 1. 1.]\n",
      "fscore: [1. 1. 1.]\n",
      "Accuracy: [1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "#User value of k=3\n",
    "k=3\n",
    "\n",
    "prediction_list=[]\n",
    "count=0\n",
    "entries=0\n",
    "for test in validation_data:\n",
    "    neighbours=get_neighbours(train_data,test,8)\n",
    "    major_class = get_votes(neighbours)\n",
    "    prediction_list.append(major_class)\n",
    "    print('classified:',major_class)\n",
    "    print(\"actual label:\",test[-1])\n",
    "    if(major_class==test[-1]):\n",
    "        print(\"Correct classification\")\n",
    "        count+=1\n",
    "    else:\n",
    "        print(\"Incorrect classification\")\n",
    "    entries+=1\n",
    "print(\"Tests:\",entries)\n",
    "print(\"Correct:\",count)\n",
    "print(\"Accuracy:\",(count/entries))\n",
    "#print(type(np.asarray(prediction_list)))\n",
    "#print(type(validation_data[:,-1]))\n",
    "accuracy = get_accuracy(np.array(prediction_list),validation_data[:,-1])\n",
    "print(\"Accuracy:\",accuracy);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Model on admission dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'[242 334 4 45 232 167 166 196 147 389 282 426 478 374 214 90 142 258 406\\n 457 317 294 162 8 500 274 11 455 35 143 422 159 163 357 289 375 241 78\\n 486 102 27 254 81 484 435 93 204 442 182 2 169 227 430 262 307 293 52 37\\n 371 299 253 404 310 496 248 135 50 447 420 150 383 73 270 117 247 108 459\\n 252 74 205 286 431 57 257 25 395 353 63 482 139 255 6 126 211 285 144 287\\n 238 461 28 360 386 140 79 92 151 58 3 44 234 136 174 456 17 354 275 265\\n 421 56 398 172 410 207 445 263 141 34 113 225 22 42 379 206 414 46 190\\n 228 62 53 438 230 352 185 15 358 266 244 330 173 463 370 272 367 305 134\\n 466 490 271 109 101 306 425 318 192 105 165 460 224 157 218 290 387 325\\n 32 302 408 409 324 429 104 40 246 193 183 277 394 124 154 418 68 451 107\\n 405 342 311 55 250 19 450 75 493 122 304 308 229 100 39 384 441 48 341 54\\n 233 292 499 41 333 340 29 33 12 469 390 249 497 261 453 436 223 76 106\\n 320 188 476 396 116 10 348 235 61 361 88 498 403 201 319 231 181 393 222\\n 111 213 480 416 210 155 470 16 437 72 280 152 300 417 195 9 465 200 129\\n 186 148 51 91 127 397 82 220 391 94 328 125 474 338 462 419 86 170 288\\n 350 327 268 149 440 433 378 335 217 119 110 301 202 413 495 309 38 458\\n 322 279 314 83 278 444 432 203 365 89 298 284 87 423 331 283 376 343 145\\n 131 492 14 178 369 381 245 485 65 382 329 21 23 5 443 237 373 153 472 26\\n 295 179 130 296 180 219 479 337 158 452 96 267 171 160 133 97 345 388 359\\n 128 407 351 467 216 226 43 434 481 260 385 251 85 112 49 80 363 303 120\\n 60 488 446 471 197 276 146 123 364 175 64 236 326 332 412 487 339 176 297\\n 103 161 336 362 164 468 36 189 168 356 464 118 240 489 177 273 347 156\\n 400 454 66 137 13 259 69 346 191 20 7 199 323 239 475 138 424 114 47 198\\n 377 70 402 30 366 31 427 67 1 399] not found in axis'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-375-768d70fe5668>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'admission_data.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Serial No.'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ajay/.local/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   3695\u001b[0m                                            \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3696\u001b[0m                                            \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3697\u001b[0;31m                                            errors=errors)\n\u001b[0m\u001b[1;32m   3698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3699\u001b[0m     @rewrite_axis_style_signature('mapper', [('copy', True),\n",
      "\u001b[0;32m/home/ajay/.local/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   3109\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3110\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3111\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ajay/.local/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   3141\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3142\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3143\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3144\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ajay/.local/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   4402\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'ignore'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4403\u001b[0m                 raise KeyError(\n\u001b[0;32m-> 4404\u001b[0;31m                     '{} not found in axis'.format(labels[mask]))\n\u001b[0m\u001b[1;32m   4405\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4406\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '[242 334 4 45 232 167 166 196 147 389 282 426 478 374 214 90 142 258 406\\n 457 317 294 162 8 500 274 11 455 35 143 422 159 163 357 289 375 241 78\\n 486 102 27 254 81 484 435 93 204 442 182 2 169 227 430 262 307 293 52 37\\n 371 299 253 404 310 496 248 135 50 447 420 150 383 73 270 117 247 108 459\\n 252 74 205 286 431 57 257 25 395 353 63 482 139 255 6 126 211 285 144 287\\n 238 461 28 360 386 140 79 92 151 58 3 44 234 136 174 456 17 354 275 265\\n 421 56 398 172 410 207 445 263 141 34 113 225 22 42 379 206 414 46 190\\n 228 62 53 438 230 352 185 15 358 266 244 330 173 463 370 272 367 305 134\\n 466 490 271 109 101 306 425 318 192 105 165 460 224 157 218 290 387 325\\n 32 302 408 409 324 429 104 40 246 193 183 277 394 124 154 418 68 451 107\\n 405 342 311 55 250 19 450 75 493 122 304 308 229 100 39 384 441 48 341 54\\n 233 292 499 41 333 340 29 33 12 469 390 249 497 261 453 436 223 76 106\\n 320 188 476 396 116 10 348 235 61 361 88 498 403 201 319 231 181 393 222\\n 111 213 480 416 210 155 470 16 437 72 280 152 300 417 195 9 465 200 129\\n 186 148 51 91 127 397 82 220 391 94 328 125 474 338 462 419 86 170 288\\n 350 327 268 149 440 433 378 335 217 119 110 301 202 413 495 309 38 458\\n 322 279 314 83 278 444 432 203 365 89 298 284 87 423 331 283 376 343 145\\n 131 492 14 178 369 381 245 485 65 382 329 21 23 5 443 237 373 153 472 26\\n 295 179 130 296 180 219 479 337 158 452 96 267 171 160 133 97 345 388 359\\n 128 407 351 467 216 226 43 434 481 260 385 251 85 112 49 80 363 303 120\\n 60 488 446 471 197 276 146 123 364 175 64 236 326 332 412 487 339 176 297\\n 103 161 336 362 164 468 36 189 168 356 464 118 240 489 177 273 347 156\\n 400 454 66 137 13 259 69 346 191 20 7 199 323 239 475 138 424 114 47 198\\n 377 70 402 30 366 31 427 67 1 399] not found in axis'"
     ]
    }
   ],
   "source": [
    "admission_train_df=[]\n",
    "admission_validation_df=[]\n",
    "split= 0.2\n",
    "df=pd.read_csv('admission_data.csv')\n",
    "dataset=list(df)\n",
    "df.drop(df.columns[1], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
